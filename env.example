# Environment configuration for Data Hub Connector Docs

# LLM provider to use: openai, ollama, internal, internal_llm
LLM_PROVIDER=internal

# Service endpoint for Ollama or Internal LLM
LLM_ENDPOINT=http://localhost:11434/api/generate

# Authentication token for LLM provider (OpenAI or Internal)
LLM_TOKEN=your_api_key_here
# For OpenAI, optionally set:
# OPENAI_API_KEY=your_openai_key_here

# Model names (for OpenAI or Ollama)
LLM_MODEL=gpt-4o
OLLAMA_MODEL=mistral
LLM_TIMEOUT=300

# Application environment: development or production
APP_ENV=development

# Comma-separated list of allowed CORS origins (e.g., UI hosts)
ALLOWED_ORIGINS=http://127.0.0.1:8000,http://localhost:8000 